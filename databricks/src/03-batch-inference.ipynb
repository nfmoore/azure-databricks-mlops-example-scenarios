{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Inference\n",
    "\n",
    "This notebook outlines a workflow for generating model predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import dependencies, define notebook parameters and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, struct\n",
    "import mlflow.pyfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define notebook parameters\n",
    "dbutils.widgets.text(\"model_uri\", \"models:/credit-default-uci-sklearn/1\")\n",
    "\n",
    "dbutils.widgets.text(\n",
    "    \"inference_dataset_table\", \"hive_metastore.default.credit_default_uci_inference\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run batch inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters\n",
    "inference_dataset_table = dbutils.widgets.get(\"inference_dataset_table\")\n",
    "model_uri = dbutils.widgets.get(\"model_uri\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read inference dataset\n",
    "inference_df = spark.read.table(inference_dataset_table).select(\n",
    "    col(\"sex\").cast(\"string\"),\n",
    "    col(\"education\").cast(\"string\"),\n",
    "    col(\"marriage\").cast(\"string\"),\n",
    "    col(\"repayment_status_1\").cast(\"string\"),\n",
    "    col(\"repayment_status_2\").cast(\"string\"),\n",
    "    col(\"repayment_status_3\").cast(\"string\"),\n",
    "    col(\"repayment_status_4\").cast(\"string\"),\n",
    "    col(\"repayment_status_5\").cast(\"string\"),\n",
    "    col(\"repayment_status_6\").cast(\"string\"),\n",
    "    col(\"credit_limit\").cast(\"double\"),\n",
    "    col(\"age\").cast(\"integer\"),\n",
    "    col(\"bill_amount_1\").cast(\"double\"),\n",
    "    col(\"bill_amount_2\").cast(\"double\"),\n",
    "    col(\"bill_amount_3\").cast(\"double\"),\n",
    "    col(\"bill_amount_4\").cast(\"double\"),\n",
    "    col(\"bill_amount_5\").cast(\"double\"),\n",
    "    col(\"bill_amount_6\").cast(\"double\"),\n",
    "    col(\"payment_amount_1\").cast(\"double\"),\n",
    "    col(\"payment_amount_2\").cast(\"double\"),\n",
    "    col(\"payment_amount_3\").cast(\"double\"),\n",
    "    col(\"payment_amount_4\").cast(\"double\"),\n",
    "    col(\"payment_amount_5\").cast(\"double\"),\n",
    "    col(\"payment_amount_6\").cast(\"double\"),\n",
    "    col(\"prediction\").cast(\"double\"),\n",
    ")\n",
    "\n",
    "# filter for records that have not predictions\n",
    "batch_df = inference_df.filter(\"prediction IS NULL\")\n",
    "\n",
    "# create spark user-defined function for model prediction\n",
    "predict = mlflow.pyfunc.spark_udf(spark, model_uri, result_type=\"double\")\n",
    "\n",
    "# generate predictions\n",
    "predictions_df = batch_df.withColumn(\"prediction\", predict(struct(*batch_df.columns)))\n",
    "\n",
    "# update inference dataset with predictions\n",
    "updated_inference_df = inference_df.filter(\"prediction IS NOT NULL\").union(\n",
    "    predictions_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write results to inference dataset table\n",
    "(\n",
    "    updated_inference_df.write.mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .saveAsTable(inference_dataset_table)\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
