{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Inference\n",
    "\n",
    "This notebook outlines a workflow for generating model predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import dependencies, define notebook parameters and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from pyspark.sql.functions import struct\n",
    "\n",
    "dbutils.widgets.text(\"model_uri\", \"models:/credit-default-uci-sklearn/1\")\n",
    "\n",
    "dbutils.widgets.text(\n",
    "    \"inference_dataset_table\", \"hive_metastore.default.credit_default_uci_inference\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run batch inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters\n",
    "inference_dataset_table = dbutils.widgets.get(\"inference_dataset_table\")\n",
    "model_uri = dbutils.widgets.get(\"model_uri\")\n",
    "\n",
    "# define column names\n",
    "id_column_name = \"id\"\n",
    "predicted_result_column_name = \"prediction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read inference dataset\n",
    "inference_df = spark.read.table(inference_dataset_table)\n",
    "\n",
    "# filter for records that have not predictions\n",
    "batch_df = spark.read.table(inference_dataset_table).filter(\"prediction IS NULL\")\n",
    "\n",
    "# create spark user-defined function for model prediction\n",
    "predict = mlflow.pyfunc.spark_udf(spark, model_uri, result_type=\"string\")\n",
    "\n",
    "# generate predictions\n",
    "predictions_df = batch_df.withColumn(\n",
    "    predicted_result_column_name, predict(struct(*batch_df.columns))\n",
    ")\n",
    "\n",
    "# update inference dataset with predictions\n",
    "updated_inference_df = inference_df.filter(\"prediction IS NOT NULL\").union(\n",
    "    predictions_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write results to inference dataset table\n",
    "updated_inference_df.write.mode(\"overwrite\").saveAsTable(inference_dataset_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
