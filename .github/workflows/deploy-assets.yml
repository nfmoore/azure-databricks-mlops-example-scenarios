name: Deploy to Databricks

on:
  # Trigger the workflow manually
  workflow_dispatch:

  # Trigger the workflow on pull request
  # pull_request:
  #   types:
  #     - opened
  #     - synchronize
  #   branches:
  #     - main

  # Trigger the workflow on push
  # push:
  #   branches:
  #     - main

env:
  AZ_CLI_VERSION: 2.59.0
  GITHUB_RUN_ID: ${{ github.run_id }}
  DEPLOYMENT_RESOURCE_GROUP_NAME: ${{ vars.DEPLOYMENT_RESOURCE_GROUP_NAME }}

permissions:
  id-token: write
  contents: read

jobs:
  train:
    name: Staging Train Model
    runs-on: ubuntu-latest
    environment:
      name: Staging
    steps:
      # Checkout the repository to the GitHub Actions runner
      - name: Checkout repo
        uses: actions/checkout@v4

        # Authenticate to Az CLI using OIDC
      - name: Azure CLI login
        uses: azure/login@v2
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

      - name: Set bundle resources
        run: |
          cd databricks
          yq eval '.include = ["resources/train_register_model.yml"]' -i ./databricks.yml
          cat ./databricks.yml

      # Deploy Databricks Bundle
      - name: Deploy Databricks Bundle
        uses: "./.github/templates/deploy-databricks-bundle"
        with:
          resource_group: ${{ env.DEPLOYMENT_RESOURCE_GROUP_NAME }}
          environment_tag: staging

      # Run train model workflow
      - name: Run workflow
        working-directory: databricks
        run: |
          # Create artifacts directory
          mkdir train-artifacts
          
          # Run train model workflow
          # databricks bundle run train_register_model_job --output json > train-artifacts/workflow-output.json

          # Display workflow output
          # cat train-artifacts/workflow-output.json

      # Upload output from workflow run
      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: train-artifacts
          path: databricks/train-artifacts
          if-no-files-found: error

  staging:
    name: Staging Deployment
    runs-on: ubuntu-latest
    needs: [train]
    environment:
      name: Staging
    steps:
      # Checkout the repository to the GitHub Actions runner
      - name: Checkout repo
        uses: actions/checkout@v4

      # Authenticate to Az CLI using OIDC
      - name: Azure CLI login
        uses: azure/login@v2
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

      # Deploy Databricks Bundle
      - name: Deploy Databricks Bundle
        uses: "./.github/templates/deploy-databricks-bundle"
        with:
          resource_group: ${{ env.DEPLOYMENT_RESOURCE_GROUP_NAME }}
          environment_tag: staging

  test:
    name: Smoke Test
    runs-on: ubuntu-latest
    needs: [staging]
    environment:
      name: Staging
    steps:
      # Checkout the repository to the GitHub Actions runner
      - name: Checkout repo
        uses: actions/checkout@v4

      # Download output from deployment
      - uses: actions/download-artifact@v4
        with:
          name: staging-artifacts

      # Set Databricks host and token environment variables and  MLFlow tracking URI
      - name: Set Databricks environment variables
        uses: azure/cli@v2
        with:
          azcliversion: ${{ env.AZ_CLI_VERSION }}
          inlineScript: |
            DATABRICKS_WORKSPACE_NAME=$(az resource list --resource-group ${{ env.DEPLOYMENT_RESOURCE_GROUP_NAME }} \
              | jq '.[] | select(.type == "Microsoft.Databricks/workspaces" and .tags.environment == "staging") | .name' -r)

            echo "DATABRICKS_HOST=https://$(az databricks workspace show --name $DATABRICKS_WORKSPACE_NAME \
              --resource-group ${{ env.DEPLOYMENT_RESOURCE_GROUP_NAME }} | jq '.workspaceUrl' -r)" >> $GITHUB_ENV
              
            echo "DATABRICKS_TOKEN=$(az account get-access-token \
              --resource 2ff814a6-3304-4ab8-85cb-cd0e6f879c1d | jq .accessToken -r)" >> $GITHUB_ENV
      
      # Set endpoint name
      - name: Set endpoint name
        run: |
          echo "ENDPOINT_NAME=$(yq eval '.variables.endpoint_name.default' databricks/serving_endpoint.yml -r)" >> $GITHUB_ENV

      # Smoke test the deployed container app
      - name: Smoke test
        run: |
          # Exit on error
          set -e
          
          STATUS_CODE=$(curl -X POST "$DATABRICKS_HOST/serving-endpoints/$ENDPOINT_NAME/invocations" \
            -H "Content-Type: application/json" \
            -u token:$DATABRICKS_TOKEN \
            -d@databricks/src/sample-request.json \
            -o response.json \
            -w "%{http_code}" \
            -s)

          # Check the status code
          if [ $STATUS_CODE -ne 200 ]; then
              echo "Got status code $status instead of expected 200"
              exit 1
          fi

          # Display the response
          cat response.json

  production:
    name: Production Deployment
    if: ${{ github.ref == 'refs/heads/main' }}
    runs-on: ubuntu-latest
    needs: [staging]
    environment:
      name: Production
    steps:
      # Checkout the repository to the GitHub Actions runner
      - name: Checkout repo
        uses: actions/checkout@v4

      # Authenticate to Az CLI using OIDC
      - name: Azure CLI login
        uses: azure/login@v2
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

      # Deploy Databricks Bundle
      - name: Deploy Databricks Bundle
        uses: "./.github/templates/deploy-databricks-bundle"
        with:
          resource_group: ${{ env.DEPLOYMENT_RESOURCE_GROUP_NAME }}
          environment_tag: staging
